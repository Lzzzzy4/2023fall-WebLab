# Web实验报告
组员：
## 一、实验目的
豆瓣 `(www.douban.com)` 是一个中国知名的社区网站，以书影音起家，用户可以在豆瓣上查看感兴趣的电影、书籍、音乐等内容，还可以关注自己感兴趣的豆友。

本实验的目的为爬取指定的电影、书籍的主页，并解析其基本信息，然后结合给定的标签信息，实现电影和书籍的检索并评估其效果；在此基础上，结合用户的评价信息及用户间社交关系，进行个性化电影、书籍推荐。
## 二、实验环境
- 操作系统：Windows 11
- 开发环境：jupyter notebook
- 软件平台：visual studio code
## 三、实验内容
### 1.爬虫
#### 要求：
针对给定的电影、书籍 ID，爬取其豆瓣主页，并解析其基本信息。

- 对于电影数据，至少爬取其基本信息、剧情简介、演职员表；

- 对于书籍数据，至少爬取其基本信息、内容简介、作者简介；

介绍使用的爬虫方式，针对所选取的爬虫方式，发现并分析平台的反爬措施，并介绍采用的应对策略；使用不同的内容解析方法，并提交所获取的数据。

#### 实现：
我们使用`request`库进行爬虫，使用`BeautifulSoup`库进行解析。

### 2.检索

#### 预处理

#### 倒排表

#### 布尔查询

#### 索引压缩

我们实现了按块存储和前缀压缩两种方式。针对id进行压缩，按块压缩默认一块包含五个条目。我们以查询书籍中包含"爱情"标签的用例进行比较。其中，$dict$代表使用python内置的平衡树实现，$block$代表使用按块压缩，$trie_1$代表仅对id进行前缀压缩，$trie_2$代表对id进行前缀压缩，并且对条目内的标签也进行前缀压缩。

|               | $dict$ | $block$ | $trie_1$ | $tire_2$ |
| ------------- | ------ | ------- | -------- | -------- |
| $run time/ms$ | 140    | 130     | 120      | 109      |
| $memory/KB$   | 10968  | 11936   | 22732    | 35560    |

对于时间分析。按块压缩可以将总条目数n减小5倍，块内查询即为遍历所有的块，但时间开销较小，所以有一定的优化提升。前缀压缩，由于trie树查询的时间复杂度为$O(n)$优于dict查询的时间复杂度$O(nlog(n))$，提升较为明显，将id条目中标签进一步压缩为trie则可以进一步提升。

对于空间分析。按块压缩中，我们需要将原本的id作为信息添加到每一个条目中，所以需要更多的内存空间。同时，按块压缩要求每一个词项占内存空间较小，可以从bit位节省空间；但是每一项书籍信息占用空间很大，对于id的压缩无法做到在bit位上节省空间。前缀压缩中，由于trie树的实现较为复杂，包含更多指针，所以需要用到更大的内存空间，并且对于id压缩使用的是数字，对于标签压缩使用的是汉字，相对英文字母有一定的劣势。

两种索引压缩在内存上表现得不理想，主要因为书籍信息的存储结构与词典略有不同，难以发挥两者的优势。

### 3.推荐